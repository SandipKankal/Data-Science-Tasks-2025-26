# -*- coding: utf-8 -*-
"""DS Defaulter 3128(2022 batch).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yh1_1vVj8cg3CtTEtieEZtAM4WBPUUlU
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical

# ============================
# Step 1: Load or Generate Data
# ============================

# For demonstration, generate dummy dataset:
# 1000 samples, 10 numeric features, binary label 'pass' or 'fail'
np.random.seed(42)
X = np.random.rand(1000, 10)  # Features

y = np.random.choice(['pass', 'fail'], 1000)  # Labels

# ======================
# Step 2: Encode Labels
# ======================

label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)  # 'fail'->0, 'pass'->1 for example

# Convert labels to categorical (one-hot encoded)
y_categorical = to_categorical(y_encoded)

# ======================
# Step 3: Train/Test Split
# ======================

X_train, X_test, y_train, y_test = train_test_split(
    X, y_categorical, test_size=0.2, random_state=42, stratify=y_categorical
)

# ======================
# Step 4: Scale Features
# ======================

scaler = StandardScaler()

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# ======================
# Step 5: Reshape for Conv1D
# Conv1D expects 3D input: (samples, timesteps, channels)
# Treat each feature as a timestep and have 1 channel
# ======================

X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# ======================
# Step 6: Build CNN Model
# ======================

model = Sequential([
    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),
    MaxPooling1D(pool_size=2),
    Dropout(0.25),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(2, activation='softmax')  # 2 classes: pass/fail
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

# ======================
# Step 7: Train the Model
# ======================

history = model.fit(
    X_train, y_train,
    epochs=20,
    batch_size=32,
    validation_split=0.1,
    verbose=1
)

# ======================
# Step 8: Evaluate on Test Data
# ======================

loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {accuracy:.2f}")

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# ============================
# Step 1: Load or Generate Data
# ============================

np.random.seed(42)
X = np.random.rand(1000, 10)  # Features
y = np.random.choice(['pass', 'fail'], 1000)  # Labels

# ======================
# Step 2: Encode Labels
# ======================

label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)  # 'fail'->0, 'pass'->1

# ======================
# Step 3: Train/Test Split
# ======================

X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
)

# ======================
# Step 4: Scale Features
# ======================

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# ======================
# Step 5: Train Logistic Regression
# ======================

log_reg = LogisticRegression(random_state=42, max_iter=1000)
log_reg.fit(X_train, y_train)

# ======================
# Step 6: Evaluate on Test Data
# ======================

y_pred = log_reg.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy:.2f}")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Load dataset
data = pd.read_csv("student-mat.csv", sep=';')

# Inspect data
print(data.head())

# Let's create a binary target variable: Pass if final grade G3 >= 10, else Fail
data['pass'] = (data['G3'] >= 10).astype(int)

# Drop G1, G2, G3 (previous grades) to avoid data leakage
data = data.drop(columns=['G1', 'G2', 'G3'])

# Encode categorical features using LabelEncoder for simplicity
categorical_cols = data.select_dtypes(include=['object']).columns

label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    data[col] = le.fit_transform(data[col])
    label_encoders[col] = le

# Features and target
X = data.drop(columns=['pass'])
y = data['pass']

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Scale features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train logistic regression model
model = LogisticRegression(max_iter=1000, random_state=42)
model.fit(X_train, y_train)

# Predict and evaluate
y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))