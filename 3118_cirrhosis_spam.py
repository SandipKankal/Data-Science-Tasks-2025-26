# -*- coding: utf-8 -*-
"""3118_Cirrhosis_Spam.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y2HYuUA-HegCHrXtb-XzFmAaOriKJnTp
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.cluster import KMeans
from sklearn.neural_network import MLPClassifier

df = pd.read_csv('cirrhosis.csv')
df.head()
df.info()
df.describe()
df.isnull().sum()

X = df.drop('Status', axis=1)  #split features and target
y = df['Status']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()   #Scale Features
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Define and Train Models
models = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "SVM": SVC(probability=True),
    "KNN": KNeighborsClassifier(),
    "Neural Network": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)
}

results = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, output_dict=True)
    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])
    results[name] = {
        'Accuracy': acc,
        'Precision': report['weighted avg']['precision'],
        'Recall': report['weighted avg']['recall'],
        'F1-Score': report['weighted avg']['f1-score'],
        'ROC-AUC': auc
    }

kmeans = KMeans(n_clusters=2, random_state=42)
kmeans.fit(X_train)
labels = kmeans.predict(X_test)

# Compare clusters to true labels roughly
acc = accuracy_score(y_test, labels)
results['KMeans'] = {'Accuracy': acc}

results_df = pd.DataFrame(results).T
print(results_df)

from sklearn.metrics import ConfusionMatrixDisplay

model = RandomForestClassifier().fit(X_train, y_train)
y_pred = model.predict(X_test)

cm = confusion_matrix(y_test, y_pred)
ConfusionMatrixDisplay(cm).plot()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Sort by accuracy
results_df_sorted = results_df.sort_values(by="Accuracy", ascending=False)

plt.figure(figsize=(10,6))
sns.barplot(x=results_df_sorted.index, y=results_df_sorted["Accuracy"], palette="viridis")
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy")
plt.xlabel("Model")
plt.xticks(rotation=30)
plt.show()

# You can also plot multiple metrics together
results_df[['Accuracy', 'Precision', 'Recall', 'F1-Score']].plot(kind='bar', figsize=(12,6))
plt.title('Model Performance Comparison')
plt.ylabel('Score')
plt.xlabel('Model')
plt.xticks(rotation=30)
plt.legend(loc='lower right')
plt.show()

plt.figure(figsize=(12,8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title("Feature Correlation Heatmap")
plt.show()

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
reduced = pca.fit_transform(X_test)

plt.figure(figsize=(8,6))
plt.scatter(reduced[:, 0], reduced[:, 1], c=labels, cmap='viridis', alpha=0.7)
plt.title("KMeans Clusters (PCA Reduced)")
plt.xlabel("PCA 1")
plt.ylabel("PCA 2")
plt.show()

#second task
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
import matplotlib.pyplot as plt

# 1. Load dataset
df1 = pd.read_csv('/content/sms_spam_collection.csv')
df1['label'] = df1['label'].map({'ham':0, 'spam':1})
df1.head()