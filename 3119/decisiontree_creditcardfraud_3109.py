# -*- coding: utf-8 -*-
"""decisiontree_creditcardfraud_3109.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oTt8waCsVz71vmu26tbRYGgFF6krkSuy
"""

import pandas as pd
df = pd.read_csv('creditcard.csv')

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load
df = pd.read_csv('creditcard.csv')
print(df.head())
print(df['Class'].value_counts())

# Split features and labels
X = df.drop('Class', axis=1)
y = df['Class']

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y)

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score

dt = DecisionTreeClassifier(max_depth=5, random_state=42)
dt.fit(X_train, y_train)

y_pred_dt = dt.predict(X_test)
print("Decision Tree Accuracy:", accuracy_score(y_test, y_pred_dt))
print(classification_report(y_test, y_pred_dt))

import tensorflow as tf
from tensorflow.keras import layers, models

nn = models.Sequential([
    layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),
    layers.Dropout(0.2),
    layers.Dense(16, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
history = nn.fit(X_train, y_train, epochs=10, batch_size=2048,
                 validation_data=(X_test, y_test), verbose=1)

loss, acc = nn.evaluate(X_test, y_test)
print(f"Neural Network Accuracy: {acc:.4f}")

best_model = nn if acc > accuracy_score(y_test, y_pred_dt) else dt
print("Best model selected:", "Neural Network" if best_model==nn else "Decision Tree")

if best_model == nn:
    nn.save("best_model.h5")
else:
    import joblib
    joblib.dump(dt, "best_model.pkl")

# ðŸ“ˆ Plot Training and Validation Accuracy
import matplotlib.pyplot as plt

plt.figure(figsize=(12,5))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Loss plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Use Neural Network predictions
y_pred_nn = (nn.predict(X_test) > 0.5).astype("int32")
cm = confusion_matrix(y_test, y_pred_nn)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap='Blues')
plt.title("Confusion Matrix - Neural Network")
plt.show()