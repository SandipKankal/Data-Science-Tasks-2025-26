# -*- coding: utf-8 -*-
"""3112_HeartDisease

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZFpN_Br9dI7p--wr4Fwblx7n6_8XS8Yz
"""

# Step 1: Import Required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, r2_score

# Machine Learning Algorithms
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

#  Step 2: Load the Dataset
df = pd.read_csv('/content/sample_data/heart_disease_dataset.csv')
df.head()

# Step 3: Basic Info
print(df.shape)
print(df.info())
print(df.isnull().sum())  # Check if any columns have missing values
df.describe()

#  Step 4: Feature & Target Split
X = df.drop('target', axis=1)
y = df['target']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# STEP 5: Clean and Handle Missing Values
import numpy as np

# Replace '?' with NaN
X = X.replace('?', np.nan)

# Convert all columns to numeric (invalid parsing will turn to NaN)
X = X.apply(pd.to_numeric, errors='coerce')

# Split dataset again after cleaning
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Impute missing values with median
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='median')
X_train = imputer.fit_transform(X_train)
X_test = imputer.transform(X_test)

# Check if any NaNs remain
print("NaNs in train:", np.isnan(X_train).sum())
print("NaNs in test:", np.isnan(X_test).sum())

# STEP 6: Feature Scaling

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# --- Initialize and train the KNN model ---
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

# --- Make predictions ---
y_pred_knn = knn.predict(X_test)

# --- Confusion Matrix ---
cm = confusion_matrix(y_test, y_pred_knn)
print("Confusion Matrix:\n")
print(cm)

# --- Optional: Display Confusion Matrix as a labeled plot ---
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_knn)
plt.title("Confusion Matrix - KNN")
plt.show()

# ==========================================================
# STEP 10: Gradient Boosting Classifier
# ==========================================================
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt

# Initialize model
gb = GradientBoostingClassifier(random_state=42)

# Train model
gb.fit(X_train, y_train)

# Predict on test data
y_pred_gb = gb.predict(X_test)

# Evaluate performance
print("ðŸŒŸ Gradient Boosting Accuracy:", accuracy_score(y_test, y_pred_gb))
print("\nClassification Report:\n", classification_report(y_test, y_pred_gb))

# Confusion Matrix Visualization
cm = confusion_matrix(y_test, y_pred_gb)
plt.figure(figsize=(4, 3))
plt.title("Gradient Boosting - Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.imshow(cm, cmap='Blues')
plt.colorbar()
for i in range(len(cm)):
    for j in range(len(cm[i])):
        plt.text(j, i, cm[i][j], ha='center', va='center', color='black')
plt.show()

# 3. Logistic Regression (Corrected & Improved)
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler

# --- Feature Scaling ---
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# --- Logistic Regression with Class Weights ---
log_reg = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)
log_reg.fit(X_train_scaled, y_train)

# --- Predictions ---
y_pred_log = log_reg.predict(X_test_scaled)

# --- Metrics ---
accuracy = accuracy_score(y_test, y_pred_log)
precision = precision_score(y_test, y_pred_log, average='weighted', zero_division=0)
recall = recall_score(y_test, y_pred_log, average='weighted', zero_division=0)
f1 = f1_score(y_test, y_pred_log, average='weighted', zero_division=0)

print("Logistic Regression Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-Score:", f1)

# --- Classification Report ---
print("\nClassification Report:\n", classification_report(y_test, y_pred_log, zero_division=0))

# --- Confusion Matrix ---
cm = confusion_matrix(y_test, y_pred_log)
print("Confusion Matrix:\n", cm)

# --- Heatmap of Confusion Matrix ---
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix Heatmap')
plt.show()

# 4. Decision Tree
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix

# --- Create and Train Decision Tree ---
dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train)

# --- Predictions ---
y_pred_dt = dt.predict(X_test)

# --- Metrics ---
accuracy = accuracy_score(y_test, y_pred_dt)
precision = precision_score(y_test, y_pred_dt, average='weighted', zero_division=0)
recall = recall_score(y_test, y_pred_dt, average='weighted', zero_division=0)
f1 = f1_score(y_test, y_pred_dt, average='weighted', zero_division=0)

print("Decision Tree Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-Score:", f1)

# --- Classification Report ---
print("\nClassification Report:\n", classification_report(y_test, y_pred_dt, zero_division=0))

# --- Confusion Matrix ---
cm = confusion_matrix(y_test, y_pred_dt)
print("Confusion Matrix:\n", cm)

# --- Heatmap of Confusion Matrix ---
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Decision Tree Confusion Matrix Heatmap')
plt.show()

# 5. Random Forest
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix

# --- Create and Train Random Forest ---
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

# --- Predictions ---
y_pred_rf = rf.predict(X_test)

# --- Metrics ---
accuracy = accuracy_score(y_test, y_pred_rf)
precision = precision_score(y_test, y_pred_rf, average='weighted', zero_division=0)
recall = recall_score(y_test, y_pred_rf, average='weighted', zero_division=0)
f1 = f1_score(y_test, y_pred_rf, average='weighted', zero_division=0)

print("Random Forest Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-Score:", f1)

# --- Classification Report ---
print("\nClassification Report:\n", classification_report(y_test, y_pred_rf, zero_division=0))

# --- Confusion Matrix ---
cm = confusion_matrix(y_test, y_pred_rf)
print("Confusion Matrix:\n", cm)

# --- Heatmap of Confusion Matrix ---
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Random Forest Confusion Matrix Heatmap')
plt.show()



import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report

# --- Feature Scaling ---
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# --- Train SVM ---
svm = SVC(kernel='rbf', random_state=42)
svm.fit(X_train_scaled, y_train)

# --- Predictions ---
y_pred_svm = svm.predict(X_test_scaled)

# --- Evaluation Metrics ---
accuracy = accuracy_score(y_test, y_pred_svm)
precision = precision_score(y_test, y_pred_svm, average='weighted', zero_division=0)
recall = recall_score(y_test, y_pred_svm, average='weighted', zero_division=0)
f1 = f1_score(y_test, y_pred_svm, average='weighted', zero_division=0)

print("ðŸ”¸ SVM Model Evaluation ðŸ”¸")
print(f"Accuracy:  {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall:    {recall:.4f}")
print(f"F1 Score:  {f1:.4f}")

# --- Classification Report ---
print("\nClassification Report:\n")
print(classification_report(y_test, y_pred_svm, zero_division=0))

# --- Confusion Matrix ---
cm = confusion_matrix(y_test, y_pred_svm)
print("Confusion Matrix:\n", cm)

# --- Confusion Matrix Heatmap ---
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix - SVM')
plt.show()