# -*- coding: utf-8 -*-
"""3127_SMSspam

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dw0Jc7O1Az9YmSmpESOS6MZW52GFeM8c
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
import matplotlib.pyplot as plt

# 1. Load dataset
df = pd.read_csv("sms_spam_collection.csv")
df['label'] = df['label'].map({'ham':0, 'spam':1})

# 2. Split into train & test
X_train, X_test, y_train, y_test = train_test_split(
    df['message'], df['label'], test_size=0.25, random_state=42)

# 3. Convert text to numbers (TF-IDF)
vec = TfidfVectorizer(max_features=1000, stop_words="english")
X_train = vec.fit_transform(X_train)
X_test = vec.transform(X_test)

# 4. Logistic Regression
log = LogisticRegression().fit(X_train, y_train)
y_pred_log = log.predict(X_test)

# 5. KNN
knn = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)

# 6. Print Accuracy
print("Logistic Regression Accuracy:", metrics.accuracy_score(y_test, y_pred_log))
print("KNN Accuracy:", metrics.accuracy_score(y_test, y_pred_knn))

# 7. Confusion Matrix - Logistic Regression
metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred_log)
plt.title("Confusion Matrix - Logistic Regression")
plt.show()

# 8. Confusion Matrix - KNN
metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred_knn)
plt.title("Confusion Matrix - KNN")
plt.show()

# 9. ROC Curve - Logistic Regression
fpr, tpr, _ = metrics.roc_curve(y_test, log.predict_proba(X_test)[:,1])
plt.plot(fpr, tpr, label="LogReg")
plt.plot([0,1],[0,1],'--')
plt.xlabel("False Positive Rate"); plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Logistic Regression")
plt.legend(); plt.show()

!pip install tensorflow pandas scikit-learn

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout

df = pd.read_csv("sms_spam_collection.csv")
print(df.head())

# Step 4: Encode labels (ham=0, spam=1)
encoder = LabelEncoder()
df['label'] = encoder.fit_transform(df['label'])

# Step 5: Tokenize and pad sequences
max_words = 5000
max_len = 100

tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(df['message'])
sequences = tokenizer.texts_to_sequences(df['message'])

X = pad_sequences(sequences, maxlen=max_len)
y = np.array(df['label'])

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 6: Build CNN model
model = Sequential([
    Embedding(max_words, 128, input_length=max_len),
    Conv1D(64, 5, activation='relu'),
    MaxPooling1D(pool_size=2),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Step 7: Compile model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Step 8: Train model
history = model.fit(X_train, y_train,
                    epochs=5,
                    batch_size=64,
                    validation_split=0.2,
                    verbose=2)

# Step 9: Evaluate model
loss, acc = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {acc:.4f}")

# Step 10: Plot training history
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('CNN Training Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()